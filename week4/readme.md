# Linear Regression

In this week's lab we are going to cover the following topics:
- Implementing _least squares_ which is the closed form solution of a simple linear regression problem.
- Implementing Gradient Descent from scratch. GD and its variants are the main algorithm of learning in almost every problem in Machine Learning.
- Using __sklearn__ package to solve a linear regression problem.
- What are polynomial features and how can we use them?
- Splitting the data to train and test sets.
- What is over fitting? What is regularization?
- Cross-validation, the standard way of hyper-parameter tuning in ML

## To Do
- Start with the notebook ["Linear_Regression_Basics.ipynb"](https://colab.research.google.com/github/michalis0/DataMining_and_MachineLearning/blob/master/week4/Linear_Regression_Basics.ipynb#scrollTo=f7a_hEfThRmX) to apply a simple linear regression model on a sample dataset. You will also review the basic concepts in linear regression by following this notebook.
- Fill in the notebook "regression_students.ipynb" as an exercise to test your skills in solving a linear regression problem.
